const { exec } = require('child_process');
const fs = require('fs/promises');
const path = require('path');
const { Anthropic } = require('@anthropic-ai/sdk');
const util = require('util');
const execPromise = util.promisify(exec);
const crypto = require('crypto'); // For generating unique filenames

// Simple logging utility with levels
const LOG_LEVELS = {
  DEBUG: 1,
  INFO: 2,
  ERROR: 3,
};

function log(level, message, ...args) {
  if (level >= currentLogLevel) {
    console.log(message, ...args);
  }
}

// Configure your API key
const ANTHROPIC_API_KEY = process.env.ANTHROPIC_API_KEY;
if (!ANTHROPIC_API_KEY) {
  console.error('Please set the ANTHROPIC_API_KEY environment variable');
  process.exit(1);
}

const anthropic = new Anthropic({
  apiKey: ANTHROPIC_API_KEY,
});
const CLAUDE_MODEL = process.env.CLAUDE_MODEL || 'claude-3-5-sonnet-20240620';

// Maximum attempts and log level can be configured via environment variables
const MAX_ATTEMPTS = parseInt(process.env.MAX_ATTEMPTS) || 3;
currentLogLevel = LOG_LEVELS[process.env.LOG_LEVEL] || LOG_LEVELS.DEBUG;

class AITestDrivenDevelopment {
  constructor(projectPath) {
    this.projectPath = projectPath;
    this.specDir = path.join(projectPath, 'spec');
    this.srcDir = path.join(projectPath, 'src');
    this.currentSpecFile = '';
    this.currentSrcFile = '';
  }

  async initialize() {

    console.log('Initializing...', currentLogLevel);
    try {
      // Create directories if they don't exist
      await fs.mkdir(this.specDir, { recursive: true });
      await fs.mkdir(this.srcDir, { recursive: true });

      // Create/update Jasmine config
      const configPath = path.join(this.projectPath, 'spec/support/jasmine.json');
      await fs.mkdir(path.join(this.projectPath, 'spec/support'), { recursive: true });

      const jasmineConfig = {
        spec_dir: 'spec',
        spec_files: ['**/*[sS]pec.js'],
        helpers: ['helpers/**/*.js'],
        stopSpecOnExpectationFailure: false,
        random: true,
      };

      await fs.writeFile(configPath, JSON.stringify(jasmineConfig, null, 2));

      // Check if Jasmine is installed
      try {
        await execPromise('npx jasmine -v');
      } catch {
        log(LOG_LEVELS.INFO, 'Jasmine not found. Installing Jasmine...');
        await execPromise('npm install --save-dev jasmine');
      }
    } catch (error) {
      console.error('Initialization error:', error);
      process.exit(1);
    }
  }

  async generateTests(description) {
    log(LOG_LEVELS.INFO, 'Generating tests...');

    const prompt = `Write Jasmine test specifications for the following functionality: ${description}. 
The implementation will be in a separate file and exported using module.exports.
Include the proper require statement at the top of the test file.
Write comprehensive tests that check both valid and edge cases.
Use modern JavaScript syntax and proper Jasmine describe/it blocks.
Example structure:
const functionName = require('../src/fileName');

describe("functionName", () => {
  it("should handle basic case", () => {
    expect(functionName(input)).toBe(expected);
  });
});`;

    try {
      const response = await anthropic.messages.create({
        model: CLAUDE_MODEL,
        max_tokens: 1000,
        messages: [{role: "user", "content": prompt}],
      });

      if (!response.content) {
        throw new Error('No test code generated by the AI.');
      }

      const testCode = response.content[0].text.trim();
      this.currentSpecFile = `${this.generateFileName(description, 'spec')}.js`;
      const filePath = path.join(this.specDir, this.currentSpecFile);

      // Ensure the test file uses the correct require path
      const baseFileName = this.generateFileName(description, 'src');
      const modifiedTestCode = testCode.replace(
        /require\(['"].*['"]\)/,
        `require('../src/${baseFileName}')`
      );

      await fs.writeFile(filePath, modifiedTestCode);
      return this.currentSpecFile;
    } catch (error) {
      console.error('Error generating tests:', error);
      process.exit(1);
    }
  }

  async runTests() {
    log(LOG_LEVELS.INFO, 'Running tests...');
    try {
      const { stdout, stderr } = await execPromise('npx jasmine');
      log(LOG_LEVELS.DEBUG, 'Raw test output:', stdout);
      const success =
        !stderr &&
        !stdout.includes('Failures:') &&
        !stdout.includes('No specs found') &&
        !stdout.includes('Error');
      return {
        success,
        output: stdout,
      };
    } catch (error) {
      log(LOG_LEVELS.ERROR, 'Test error:', error);
      return { success: false, output: error.stdout || error.message };
    }
  }

  async implementCode(testContent, previousImplementation = '') {
    log(LOG_LEVELS.INFO, 'Implementing code based on tests...');

    const prompt = `Given these Jasmine tests:\n\n${testContent}\n\n${
      previousImplementation ? 'And this previous implementation that failed:\n\n' + previousImplementation + '\n\n' : ''
    }Write the JavaScript implementation code that will make these tests pass. 
Export the implementation using module.exports = functionName;
Only provide the Javascript implementation code, no tests.`;

try {
    const response = await anthropic.messages.create({
        model: CLAUDE_MODEL,
        max_tokens: 1000,
        messages: [{role: "user", "content": prompt}],
    });
    
      if (!response.content) {
        throw new Error('No implementation code generated by the AI.');
      }

      const implementationCode = response.content[0].text.trim();
      const baseFileName = this.generateFileName(testContent, 'src');
      this.currentSrcFile = `${baseFileName}.js`;

      await fs.writeFile(path.join(this.srcDir, this.currentSrcFile), implementationCode);

      // Log the contents of both files for debugging
      log(LOG_LEVELS.DEBUG, '\nTest file contents:');
      log(LOG_LEVELS.DEBUG, await this.readFile(path.join(this.specDir, this.currentSpecFile)));
      log(LOG_LEVELS.DEBUG, '\nImplementation file contents:');
      log(LOG_LEVELS.DEBUG, implementationCode);

      return { fileName: this.currentSrcFile, code: implementationCode };
    } catch (error) {
      console.error('Error implementing code:', error);
      process.exit(1);
    }
  }

  async fixFailingTests(testContent, implementation, testOutput) {
    log(LOG_LEVELS.INFO, 'Fixing failing tests...');

    const prompt = `ONLY JAVASCRIPT CODE. NO EXPLAINATION. Given these failing tests:\n\n${testContent}\n\n
And this implementation:\n\n${implementation}\n\n
And this test output:\n\n${testOutput}\n\n
Please provide a fixed implementation that will make all tests pass.
Export the implementation using module.exports = functionName;
Only provide the implementation code, no tests. Only JavaScript.`;

    try {
      const response = await anthropic.messages.create({
        model: CLAUDE_MODEL,
        max_tokens: 1000,
        messages: [{role: "user", "content": prompt}],
      });

      if (!response.content) {
        throw new Error('No fixed implementation generated by the AI.');
      }

      const fixedImplementation = response.content[0].text.trim();
      return fixedImplementation;
    } catch (error) {
      console.error('Error fixing implementation:', error);
      process.exit(1);
    }
  }

  generateFileName(content, type) {
    // Generate a reasonable, unique filename from the content
    const hash = crypto.createHash('md5').update(content).digest('hex').slice(0, 6);
    const baseName = content
      .toLowerCase()
      .replace(/[^\w\s]/g, '')
      .split(/\s+/)
      .slice(0, 3)
      .join('_');
    // const fileName = `${baseName || 'implementation'}_${hash}_${type}`;
    const fileName = `${'' || 'implementation'}_${type}`;
    return fileName;
  }

  async readFile(filePath) {
    try {
      return await fs.readFile(filePath, 'utf8');
    } catch (error) {
      console.error(`Error reading file ${filePath}:`, error);
      return null;
    }
  }
}

async function main() {
  const tdd = new AITestDrivenDevelopment(process.cwd());
  await tdd.initialize();

  // Get the feature description from command line arguments
  const description = process.argv.slice(2).join(' ');
  if (!description) {
    console.error('Please provide a feature description as an argument');
    process.exit(1);
  }

  // Generate initial tests
  const specFileName = await tdd.generateTests(description);
  log(LOG_LEVELS.INFO, `Generated test file: ${specFileName}`);

  let testsPassing = false;
  let attempts = 0;

  while (!testsPassing && attempts < MAX_ATTEMPTS) {
    attempts++;
    log(LOG_LEVELS.INFO, `\nAttempt ${attempts} of ${MAX_ATTEMPTS}`);

    // Read the current test content
    const testContent = await tdd.readFile(path.join(tdd.specDir, specFileName));
    if (!testContent) continue;

    // Implement or fix the code
    const previousImplementation =
      attempts > 1 ? await tdd.readFile(path.join(tdd.srcDir, tdd.currentSrcFile)) : '';
    const implementation = await tdd.implementCode(testContent, previousImplementation);

    log(LOG_LEVELS.INFO, `Generated implementation file: ${implementation.fileName}`);

    // Run the tests
    const testResult = await tdd.runTests();
    log(LOG_LEVELS.INFO, '\nTest Results:');
    log(LOG_LEVELS.INFO, testResult.output);

    if (testResult.success) {
      testsPassing = true;
      log(LOG_LEVELS.INFO, '\nAll tests passed! ðŸŽ‰');
    } else if (attempts < MAX_ATTEMPTS) {
      log(LOG_LEVELS.INFO, '\nTests failed. Attempting to fix...');
      const fixedImplementation = await tdd.fixFailingTests(
        testContent,
        implementation.code,
        testResult.output
      );
      await fs.writeFile(
        path.join(tdd.srcDir, tdd.currentSrcFile),
        fixedImplementation
      );
    }
  }

  if (!testsPassing) {
    console.error(`\nFailed to make tests pass after ${MAX_ATTEMPTS} attempts.`);
    process.exit(1);
  }
}

// Run the program
main().catch((error) => {
  console.error('Error:', error);
  process.exit(1);
});
